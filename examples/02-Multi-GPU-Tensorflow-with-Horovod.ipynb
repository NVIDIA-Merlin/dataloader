{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb28e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77464844",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Multi-GPU training with Tensorflow and Horovod\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow) container.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook we will look at multi-GPU training with Tensorflow and Horovod. [Horovod] is a distributed deep learning framework that aims to make distributed deep learning fast and easy to use.\n",
    "\n",
    "In this example, we will provide a simple pipeline to train a MatrixFactorization Model in TensorFlow on multiple GPUs (for the example we will use two but this method can be easily extended to use more).\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training on multiple GPUs with Merlind Dataloader and Horovod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5598ae",
   "metadata": {},
   "source": [
    "# Downloading and preparing the dataset\n",
    "\n",
    "We will base our example on the  [MovieLens25M](https://grouplens.org/datasets/movielens/25m/) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd46306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.core.utils import download_file\n",
    "from merlin.core.dispatch import get_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591f8c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading ml-25m.zip: 262MB [00:06, 42.7MB/s]                            \n",
      "unzipping files: 100%|██████████| 8/8 [00:08<00:00,  1.03s/files]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '/workspace'\n",
    "download_file(\"http://files.grouplens.org/datasets/movielens/ml-25m.zip\", DATA_PATH + \"/ml-25m.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc70934",
   "metadata": {},
   "source": [
    "# Training a TensorFlow Keras Model with Merlin dataloader and Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b46668",
   "metadata": {},
   "source": [
    "We will be training with two processes on two GPUs. We will implement data parallel training. Each GPU will have an exact copy of our model, however it will train on different subsets of data.\n",
    "\n",
    "Let's us split our train data into two parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65e5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = get_lib().read_csv(DATA_PATH + '/ml-25m/ratings.csv')\n",
    "\n",
    "ratings[:int(0.5*ratings.shape[0])].to_parquet(DATA_PATH + '/train_0.parquet')\n",
    "ratings[int(0.5*ratings.shape[0]):].to_parquet(DATA_PATH + '/train_1.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a65b4",
   "metadata": {},
   "source": [
    "Let us now take a closer look at what else we will need to train with Horovod.\n",
    "\n",
    "### Write the training script to a file\n",
    "\n",
    "We need to have a `.py` file we will be able to load into each process using `horovodrun`. \n",
    "\n",
    "### Set `CUDA visible devices` correctly inside each process\n",
    "\n",
    "We need to set the visible device in each process to its `rank`. This way process with `rank 0` will use the zeroth GPU, process with `rank 1` will use the first GPU, and so on. This ensures that each worker can access only a single GPU.\n",
    "\n",
    "Additionally, we will use the `rank` infromation to select the correct parquet file to load per worker (`DATA_PATH + f'/train_{hvd.local_rank()}.parquet'`)\n",
    "\n",
    "**Important: Individual parquet files require to have the same number of batches. If one worker has more batches than another, the training process will freeze. At one point during the training process, the worker with more batches waits for the gradients from the worker with fewer batches. But the worker with fewer batches finished the training run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbe17a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tf_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './tf_trainer.py'\n",
    "\n",
    "from merlin.io import Dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow.keras as hvd\n",
    "import os\n",
    "from glob import glob\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "hvd.init()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "\n",
    "from merlin.loader.tensorflow import Loader\n",
    "\n",
    "DATA_PATH = '/workspace'\n",
    "\n",
    "from merlin.core.dispatch import get_lib\n",
    "dataset = Dataset(glob(DATA_PATH + f'/train_{hvd.local_rank()}.parquet'), part_mem_fraction=0.001)\n",
    "loader = Loader(dataset, batch_size=1024, global_rank=hvd.rank(), global_size=hvd.size())\n",
    "\n",
    "batch = next(iter(loader))\n",
    "\n",
    "label_column = 'rating'\n",
    "\n",
    "def process_batch(data, _):\n",
    "    x = {col: data[col] for col in data.keys() if col != label_column}\n",
    "    y = data[label_column]\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "loader._map_fns = [process_batch]\n",
    "\n",
    "\n",
    "class MatrixFactorization(tf.keras.Model):\n",
    "    def __init__(self, n_factors):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = tf.keras.layers.Embedding(162541, n_factors)\n",
    "        self.movie_embeddings = tf.keras.layers.Embedding(209171, n_factors)\n",
    "\n",
    "    def call(self, batch, training=False):\n",
    "        user_embs = self.user_embeddings(batch['userId'])\n",
    "        movie_embs = self.movie_embeddings(batch['movieId'])\n",
    "\n",
    "        tensor = (tf.squeeze(user_embs) * tf.squeeze(movie_embs))\n",
    "        return tf.reduce_sum(tensor, 1)\n",
    "    \n",
    "model = MatrixFactorization(64)\n",
    "opt = tf.keras.optimizers.Adam(1e-2  * hvd.size())\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.MeanSquaredError(), experimental_run_tf_function=False)\n",
    "\n",
    "model.fit(loader, epochs=1, callbacks=[hvd.callbacks.BroadcastGlobalVariablesCallback(0)], verbose=1 if hvd.rank() == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5e9b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,0]<stderr>:2022-12-06 06:08:06.849308: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "[1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[1,1]<stderr>:2022-12-06 06:08:06.849480: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "[1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[1,0]<stderr>:2022-12-06 06:08:07.048602: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "[1,0]<stderr>:2022-12-06 06:08:07.048936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16255 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "[1,1]<stderr>:2022-12-06 06:08:08.842132: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 1\n",
      "[1,1]<stderr>:2022-12-06 06:08:08.842382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30655 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:0b:00.0, compute capability: 7.0\n",
      "[1,1]<stderr>:/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "[1,1]<stderr>:  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "[1,1]<stderr>:Traceback (most recent call last):\n",
      "[1,1]<stderr>:  File \"tf_trainer.py\", line 27, in <module>\n",
      "[1,1]<stderr>:    batch = next(iter(loader))\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 500, in __iter__\n",
      "[1,1]<stderr>:    for item in (self[i] for i in range(len(self))):\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 500, in <genexpr>\n",
      "[1,1]<stderr>:    for item in (self[i] for i in range(len(self))):\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/tensorflow.py\", line 146, in __getitem__\n",
      "[1,1]<stderr>:    return LoaderBase.__next__(self)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/loader_base.py\", line 274, in __next__\n",
      "[1,1]<stderr>:    return self._get_next_batch()\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/loader_base.py\", line 307, in _get_next_batch\n",
      "[1,1]<stderr>:    self._fetch_chunk()\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/loader_base.py\", line 286, in _fetch_chunk\n",
      "[1,1]<stderr>:    raise chunks\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/loader_base.py\", line 715, in load_chunks\n",
      "[1,1]<stderr>:    self.chunk_logic(itr)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py\", line 101, in inner\n",
      "[1,1]<stderr>:    result = func(*args, **kwargs)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/loader_base.py\", line 697, in chunk_logic\n",
      "[1,1]<stderr>:    chunks = self.dataloader.make_tensors(chunks, self.dataloader._use_nnz)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py\", line 101, in inner\n",
      "[1,1]<stderr>:    result = func(*args, **kwargs)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/loader_base.py\", line 350, in make_tensors\n",
      "[1,1]<stderr>:    chunks, names = self._create_tensors(gdf)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py\", line 101, in inner\n",
      "[1,1]<stderr>:    result = func(*args, **kwargs)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/loader_base.py\", line 527, in _create_tensors\n",
      "[1,1]<stderr>:    x = self._to_tensor(gdf_i[scalars])\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/tensorflow.py\", line 213, in _to_tensor\n",
      "[1,1]<stderr>:    x = self._unpack(dlpack)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/merlin/loader/tensorflow.py\", line 195, in _unpack\n",
      "[1,1]<stderr>:    return from_dlpack(gdf)\n",
      "[1,1]<stderr>:  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/dlpack/dlpack.py\", line 63, in from_dlpack\n",
      "[1,1]<stderr>:    return pywrap_tfe.TFE_FromDlpackCapsule(dlcapsule, context.context()._handle)  # pylint: disable=protected-access\n",
      "[1,1]<stderr>:tensorflow.python.framework.errors_impl.InvalidArgumentError: GPU:1 unknown device.\n",
      "[1,1]<stderr>:[3803308:01289] *** Process received signal ***\n",
      "[1,1]<stderr>:[3803308:01289] Signal: Segmentation fault (11)\n",
      "[1,1]<stderr>:[3803308:01289] Signal code:  (128)\n",
      "[1,1]<stderr>:[3803308:01289] Failing at address: (nil)\n",
      "[1,1]<stderr>:[3803308:01289] [ 0] [1,1]<stderr>:/usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420)[0x7f22fac2c420]\n",
      "[1,1]<stderr>:[3803308:01289] [ 1] /usr/local/lib/python3.8/dist-packages/cupy/_core/dlpack.cpython-38-x86_64-linux-gnu.so(+0x8a19)[0x7f21086c8a19]\n",
      "[1,1]<stderr>:[3803308:01289] [ 2] [1,1]<stderr>:python[0x43fcec]\n",
      "[1,1]<stderr>:[3803308:01289] [ 3] [1,1]<stderr>:python[0x5ee8c0]\n",
      "[1,1]<stderr>:[3803308:01289] [ 4] [1,1]<stderr>:python[0x544e48]\n",
      "[1,1]<stderr>:[3803308:01289] [ 5] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [ 6] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [ 7] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [ 8] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [ 9] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [10] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [11] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [12] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [13] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [14] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [15] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [16] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [17] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [18] [1,1]<stderr>:python[0x544e9a]\n",
      "[1,1]<stderr>:[3803308:01289] [19] [1,1]<stderr>:python[0x5f2a66]\n",
      "[1,1]<stderr>:[3803308:01289] [20] [1,1]<stderr>:python[0x4f0908]\n",
      "[1,1]<stderr>:[3803308:01289] [21] [1,1]<stderr>:python(_PyGC_CollectNoFail+0x2f)[0x671eff]\n",
      "[1,1]<stderr>:[3803308:01289] [22] [1,1]<stderr>:python(PyImport_Cleanup+0x244)[0x687ca4]\n",
      "[1,1]<stderr>:[3803308:01289] [23] [1,1]<stderr>:python(Py_FinalizeEx+0x7f)[0x682aef]\n",
      "[1,1]<stderr>:[3803308:01289] [24] [1,1]<stderr>:python(Py_RunMain+0x32d)[0x6b9e4d]\n",
      "[1,1]<stderr>:[3803308:01289] [25] [1,1]<stderr>:python(Py_BytesMain+0x2d)[0x6ba0bd]\n",
      "[1,1]<stderr>:[3803308:01289] [26] [1,1]<stderr>:/usr/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3)[0x7f22fac5f083]\n",
      "[1,1]<stderr>:[3803308:01289] [27] [1,1]<stderr>:python(_start+0x2e)[0x5fc5fe]\n",
      "[1,1]<stderr>:[3803308:01289] *** End of error message ***\n",
      "--------------------------------------------------------------------------\n",
      "Primary job  terminated normally, but 1 process returned\n",
      "a non-zero exit code. Per user-direction, the job has been aborted.\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "mpirun noticed that process rank 1 with PID 0 on node 3803308 exited on signal 11 (Segmentation fault).\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 2 python tf_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93151b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  6 06:09:17 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    47W / 163W |   1456MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    40W / 163W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d97fe2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We demonstrated how to train a TensorFlow Keras model with the Merlin dataloader on multiple GPUs using Horovod.\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "Merlin dataloader is part of NVIDIA Merlin, a open source framework for recommender systems. In this example, we looked only on a specific use-case to accelerate existing training pipelines. We provide more libraries to make recommender system pipelines easier and faster to work with:\n",
    "\n",
    "* [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) is a library to accelerate and scale feature engineering\n",
    "* [Merlin Models](https://github.com/NVIDIA-Merlin/models) is a library with high-quality implementations of popular recommender systems architectures\n",
    "\n",
    "The libraries are designed to work closely together. We recommend to check out our examples:\n",
    "\n",
    "* [Getting Started with NVTabular: Process Tabular Data On GPU](https://github.com/NVIDIA-Merlin/NVTabular/blob/main/examples/01-Getting-started.ipynb)\n",
    "* [Getting Started with Merlin Models: Develop a Model for MovieLens](https://github.com/NVIDIA-Merlin/models/blob/main/examples/01-Getting-started.ipynb)\n",
    "\n",
    "In the example, [From ETL to Training RecSys models - NVTabular and Merlin Models integrated example](https://github.com/NVIDIA-Merlin/models/blob/main/examples/02-Merlin-Models-and-NVTabular-integration.ipynb), we explain how the close collaboration works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
