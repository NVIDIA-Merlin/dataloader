{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb28e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77464844",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Getting Started with `Merlin dataloader`\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow) container.\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Merlin dataloader](https://github.com/NVIDIA-Merlin/dataloader) is a library for constructing highly optimized dataloaders to feed `Tensorflow/Keras` and `PyTorch` models during training. You preprocess your data using a [Merlin NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) workflow and hand the dataset over to `Merlin dataloader`.\n",
    "\n",
    "In this notebook we will download the Movielens dataset consisting of movie ratings. We will load the data directly from a csv file residing on disk into a `Merlin Dataset`. Subsequently, we will construct a dataloader and build a simple `MatrixFactorization` model in vanilla PyTorch.\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Understand `Merlin dataloader` high-level concepts\n",
    "- Become familar  with `Merlin dataloader` and understand the shape of the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5598ae",
   "metadata": {},
   "source": [
    "# Downloading the dataset\n",
    "\n",
    "### MovieLens25M\n",
    "\n",
    "The [MovieLens25M](https://grouplens.org/datasets/movielens/25m/) is a popular dataset for recommender systems and is widely used in academic publications. The dataset contains 25M movie ratings for 62,000 movies given by 162,000 users. Many projects use only the user/item/rating information of MovieLens, but the original dataset provides metadata for the movies, as well. For example, which genres a movie has.\n",
    "\n",
    "In this notebook, we will only use the user-movie pairs along with the ratings a user assigned to the movie.\n",
    "\n",
    "Let's begin by downloading the [`MovieLens 25M Dataset`](https://grouplens.org/datasets/movielens/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d257d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-16 00:31:17--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261978986 (250M) [application/zip]\n",
      "Saving to: ‘ml-25m.zip’\n",
      "\n",
      "ml-25m.zip          100%[===================>] 249.84M  5.13MB/s    in 48s     \n",
      "\n",
      "2022-11-16 00:32:07 (5.25 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3446b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!apt update\n",
    "!apt install unzip\n",
    "!unzip -q ml-25m.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c29f121",
   "metadata": {},
   "source": [
    "We have now downloaded and extracted the data and can read in the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80cb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.core.dispatch import get_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65e5ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = get_lib().read_csv('ml-25m/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffce3a",
   "metadata": {},
   "source": [
    "The `ratings.csv` file stores ratings a user has given a movie. Let's load the data directly from disk into a `Merlin Dataset` and train a simple `MatrixFactorization` model that we will construct in `Tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26b46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.io import Dataset\n",
    "\n",
    "dataset = Dataset('ml-25m/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d53c8a",
   "metadata": {},
   "source": [
    "Let us now instantiate the `dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c60070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2022-11-16 01:52:40.081385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:40.081755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:40.081949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from merlin.loader.tensorflow import Loader\n",
    "loader = Loader(dataset, batch_size=65536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352265c",
   "metadata": {},
   "source": [
    "As is, the `loader` will output a batch that will consist of a tuple with dictionary with tensors and `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc8b31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 01:52:41.673770: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 01:52:41.674969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:41.675174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:41.675330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:41.675630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:41.675799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:41.675958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:52:41.676077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'userId': <tf.Tensor: shape=(65536, 1), dtype=int64, numpy=\n",
       "  array([[ 76153],\n",
       "         [158537],\n",
       "         [ 73683],\n",
       "         ...,\n",
       "         [128780],\n",
       "         [106222],\n",
       "         [126524]])>,\n",
       "  'movieId': <tf.Tensor: shape=(65536, 1), dtype=int64, numpy=\n",
       "  array([[96610],\n",
       "         [ 1242],\n",
       "         [ 1047],\n",
       "         ...,\n",
       "         [ 5610],\n",
       "         [ 2028],\n",
       "         [78499]])>,\n",
       "  'timestamp': <tf.Tensor: shape=(65536, 1), dtype=int64, numpy=\n",
       "  array([[1544993745],\n",
       "         [1090906537],\n",
       "         [ 862850547],\n",
       "         ...,\n",
       "         [1078376169],\n",
       "         [1434313376],\n",
       "         [1527204337]])>,\n",
       "  'rating': <tf.Tensor: shape=(65536, 1), dtype=float64, numpy=\n",
       "  array([[5. ],\n",
       "         [3.5],\n",
       "         [5. ],\n",
       "         ...,\n",
       "         [3. ],\n",
       "         [5. ],\n",
       "         [3. ]])>},\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792a92d",
   "metadata": {},
   "source": [
    "What `Tensorflow` expects to see are targets as the 2nd position in the tuple.\n",
    "\n",
    "Let's write a function that will transform the batch to an appropriate shape on the fly for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f1b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(data, _):\n",
    "    return ({'userId': data['userId'], 'movieId': data['movieId']}, data['rating'])\n",
    "\n",
    "loader._map_fns = [process_batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a4d4f",
   "metadata": {},
   "source": [
    "We now have the data in the shape that `Tensorflow` expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9759b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': <tf.Tensor: shape=(65536, 1), dtype=int64, numpy=\n",
       "  array([[  8168],\n",
       "         [ 63125],\n",
       "         [127567],\n",
       "         ...,\n",
       "         [ 55148],\n",
       "         [ 88981],\n",
       "         [ 25953]])>,\n",
       "  'movieId': <tf.Tensor: shape=(65536, 1), dtype=int64, numpy=\n",
       "  array([[ 2952],\n",
       "         [ 1250],\n",
       "         [  293],\n",
       "         ...,\n",
       "         [68358],\n",
       "         [99114],\n",
       "         [55241]])>},\n",
       " <tf.Tensor: shape=(65536, 1), dtype=float64, numpy=\n",
       " array([[3.5],\n",
       "        [3. ],\n",
       "        [4. ],\n",
       "        ...,\n",
       "        [4. ],\n",
       "        [4. ],\n",
       "        [0.5]])>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af193bd9",
   "metadata": {},
   "source": [
    "Let us now construct a simple MatrixFactorization model and train for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d9a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MatrixFactorization(tf.keras.Model):\n",
    "    def __init__(self, n_factors):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = tf.keras.layers.Embedding(ratings['userId'].max(), n_factors)\n",
    "        self.movie_embeddings = tf.keras.layers.Embedding(ratings['movieId'].max(), n_factors)\n",
    "        \n",
    "    def call(self, batch, training=False):\n",
    "        user_embs = self.user_embeddings(batch['userId'])\n",
    "        movie_embs = self.movie_embeddings(batch['movieId'])\n",
    "        \n",
    "        tensor = (tf.squeeze(user_embs) * tf.squeeze(movie_embs))\n",
    "        return tf.reduce_sum(tensor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "561e5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(64)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-2), loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9bf5c7",
   "metadata": {},
   "source": [
    "Let's first calculate the Mean Squared Error loss before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5ae298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 2s 2ms/step - loss: 13.6133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.613324165344238"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa759a",
   "metadata": {},
   "source": [
    "Let us now train for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1724838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 01:53:06.514200: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_LEGACY_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'mean_squared_error/cond/output/_11'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 3s 6ms/step - loss: 7.0560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f118af504c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(loader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb3519ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 1s 2ms/step - loss: 6.1694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.169384479522705"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d97fe2",
   "metadata": {},
   "source": [
    "The model has improved and has run for a single epoch, training on all 25_000_000 datapoints, in record time!\n",
    "\n",
    "In a more realistic scenario we would have singled out a validation dataset, trained for more epochs, optimized hyperparameters and so on.\n",
    "\n",
    "Nonetheless, the objective here was to quickly show you the ropes on integrating `Merlin dataloader` with `Tensorflow`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-tensorflow:latest"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
