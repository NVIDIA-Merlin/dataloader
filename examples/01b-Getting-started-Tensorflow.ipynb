{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb28e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77464844",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Getting Started with `Merlin dataloader`\n",
    "\n",
    "This notebook is created using the latest stable [merlin-pytorch](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-pytorch) container.\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Merlin dataloader](https://github.com/NVIDIA-Merlin/dataloader) is a library for constructing highly optimized dataloaders to feed `Tensorflow/Keras` and `PyTorch` models during training. You preprocess your data using a [Merlin NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) workflow and hand the dataset over to `Merlin dataloader`.\n",
    "\n",
    "In this notebook we will download the Movielens dataset consisting of movie ratings. We will briefly process the data using NVTabular and output it to a `Merlin Dataset`. Subsequently, we will construct a dataloader and build a simple `MatrixFactorization` model in vanilla PyTorch.\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Learn how `Merlin dataloader` integrates with `NVTabular` (a library for preprocessing tabular data on the GPU)\n",
    "- Understand `Merlin dataloader` high-level concepts\n",
    "- Use `Merlin dataloader` to train a `PyTorch` model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5598ae",
   "metadata": {},
   "source": [
    "# Downloading the dataset\n",
    "\n",
    "### MovieLens25M\n",
    "\n",
    "The [MovieLens25M](https://grouplens.org/datasets/movielens/25m/) is a popular dataset for recommender systems and is widely used in academic publications. The dataset contains 25M movie ratings for 62,000 movies given by 162,000 users. Many projects use only the user/item/rating information of MovieLens, but the original dataset provides metadata for the movies, as well. For example, which genres a movie has.\n",
    "\n",
    "In this notebook, we will only use the user-movie pairs along with the ratings a user assigned to the movie.\n",
    "\n",
    "Let's begin by downloading the [`MovieLens 25M Dataset`](https://grouplens.org/datasets/movielens/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821cbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ml-25m*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f88b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01a-Getting-started-Pytorch.ipynb     README.md    index.html\r\n",
      "01b-Getting-started-Tensorflow.ipynb  \u001b[0m\u001b[01;34mcategories\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d257d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-16 00:31:17--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261978986 (250M) [application/zip]\n",
      "Saving to: ‘ml-25m.zip’\n",
      "\n",
      "ml-25m.zip          100%[===================>] 249.84M  5.13MB/s    in 48s     \n",
      "\n",
      "2022-11-16 00:32:07 (5.25 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3446b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!apt update\n",
    "!apt install unzip\n",
    "!unzip -q ml-25m.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c29f121",
   "metadata": {},
   "source": [
    "We have now downloaded and extracted the data and can read in the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80cb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.core.dispatch import get_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65e5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = get_lib().read_csv('ml-25m/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffce3a",
   "metadata": {},
   "source": [
    "The `ratings.csv` file stores ratings a user has given a movie. Let's process the data, pass the resultant NVTabular dataset to `Merlin dataloader` and train a simple MatrixFactorization model that we will construct in `PyTorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10daa5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538f4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular import *\n",
    "from nvtabular import ops\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "dataset = Dataset(ratings)\n",
    "\n",
    "user_and_movie_ids = ['userId', 'movieId'] >> ops.Categorify(freq_threshold=100)\n",
    "rating = ['rating'] >> ops.AddTags([Tags.TARGET])\n",
    "workflow = Workflow(user_and_movie_ids + rating)\n",
    "\n",
    "processed = workflow.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d53c8a",
   "metadata": {},
   "source": [
    "We processed our `Merlin Dataset` using NVTabulars and performed the operations on the GPU. If you would like to learn more about the NVTabular library, please take a look [here](https://github.com/NVIDIA-Merlin/NVTabular).\n",
    "\n",
    "Now that we have preprocessed our data, let's instantiate the `dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34f1b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2022-11-16 00:32:56.129491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.129853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.130008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from merlin.loader.tensorflow import Loader\n",
    "loader = Loader(processed, batch_size=65536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8b31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 00:32:56.323968: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 00:32:56.325172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.325378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.325533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.325843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.326009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.326169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 00:32:56.326288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce1e0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting merlin-dataloader\n",
      "  Downloading merlin-dataloader-0.0.2.tar.gz (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: merlin-core in /usr/local/lib/python3.8/dist-packages (from merlin-dataloader) (0.8.0)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (0.56.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (21.3)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (3.19.6)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (4.64.1)\n",
      "Requirement already satisfied: fsspec==2022.5.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (2022.5.0)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (1.2.5)\n",
      "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (2022.5.1)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (1.10.0)\n",
      "Requirement already satisfied: distributed>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (2022.5.1)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (7.0.0)\n",
      "Requirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core->merlin-dataloader) (1.3.5)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core->merlin-dataloader) (1.22.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core->merlin-dataloader) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.54->merlin-core->merlin-dataloader) (45.2.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core->merlin-dataloader) (5.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->merlin-core->merlin-dataloader) (3.0.9)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core->merlin-dataloader) (0.4.3)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core->merlin-dataloader) (1.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core->merlin-dataloader) (6.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core->merlin-dataloader) (2.2.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core->merlin-dataloader) (0.12.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core->merlin-dataloader) (1.3.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core->merlin-dataloader) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core->merlin-dataloader) (1.56.4)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (6.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (1.0.4)\n",
      "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (8.1.3)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (2.4.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (1.26.12)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (2.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (3.1.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core->merlin-dataloader) (5.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core->merlin-dataloader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core->merlin-dataloader) (2022.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core->merlin-dataloader) (3.10.0)\n",
      "Requirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core->merlin-dataloader) (6.0.2)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core->merlin-dataloader) (4.1.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2022.3.0->merlin-core->merlin-dataloader) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed>=2022.3.0->merlin-core->merlin-dataloader) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas<1.4.0dev0,>=1.2.0->merlin-core->merlin-dataloader) (1.14.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core->merlin-dataloader) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core->merlin-dataloader) (4.0.0)\n",
      "Building wheels for collected packages: merlin-dataloader\n",
      "  Building wheel for merlin-dataloader (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for merlin-dataloader: filename=merlin_dataloader-0.0.2-py3-none-any.whl size=29203 sha256=91d964a33714577018cd70fed533f3eb37104e4976e057d63488ea38e6726b83\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/ce/8c/31476c01e0b5a2278110fe2092bdd911efb0e5b83d0d3550ca\n",
      "Successfully built merlin-dataloader\n",
      "Installing collected packages: merlin-dataloader\n",
      "Successfully installed merlin-dataloader-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install merlin-dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b56e2",
   "metadata": {},
   "source": [
    "From the `loader` we obtain a batch of data, a dictionary of tensors that have already been moved to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7794881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': <tf.Tensor: shape=(65536, 1), dtype=int64, numpy=\n",
       "  array([[10893],\n",
       "         [   24],\n",
       "         [26219],\n",
       "         ...,\n",
       "         [23129],\n",
       "         [ 3882],\n",
       "         [41289]])>,\n",
       "  'movieId': <tf.Tensor: shape=(65536, 1), dtype=int64, numpy=\n",
       "  array([[1512],\n",
       "         [   0],\n",
       "         [ 561],\n",
       "         ...,\n",
       "         [2174],\n",
       "         [1467],\n",
       "         [ 619]])>},\n",
       " <tf.Tensor: shape=(65536, 1), dtype=float64, numpy=\n",
       " array([[3. ],\n",
       "        [4. ],\n",
       "        [4.5],\n",
       "        ...,\n",
       "        [3. ],\n",
       "        [2.5],\n",
       "        [5. ]])>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af193bd9",
   "metadata": {},
   "source": [
    "Let us now construct a simple MatrixFactorization model and train for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89d9a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MatrixFactorization(tf.keras.Model):\n",
    "    def __init__(self, n_factors):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = tf.keras.layers.Embedding(processed.schema['userId'].properties['domain']['max'], n_factors)\n",
    "        self.movie_embeddings = tf.keras.layers.Embedding(processed.schema['movieId'].properties['domain']['max'], n_factors)\n",
    "        \n",
    "    def call(self, batch, training=False):\n",
    "        user_embs = self.user_embeddings(batch['userId'])\n",
    "        movie_embs = self.movie_embeddings(batch['movieId'])\n",
    "        \n",
    "        tensor = (tf.squeeze(user_embs) * tf.squeeze(movie_embs))\n",
    "        return tf.reduce_sum(tensor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561e5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(64)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-2), loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9bf5c7",
   "metadata": {},
   "source": [
    "Let's first calculate the Mean Squared Error loss before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5ae298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 1s 2ms/step - loss: 13.6133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.613266944885254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa759a",
   "metadata": {},
   "source": [
    "Let us now train for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1724838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 00:39:56.476031: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_LEGACY_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'mean_squared_error/cond/output/_11'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 2s 4ms/step - loss: 1.5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8d0d1d8b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(loader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb3519ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 1s 2ms/step - loss: 0.7724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.772408127784729"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d97fe2",
   "metadata": {},
   "source": [
    "The model has improved and has run for a single epoch, training on all 25_000_000 datapoints, in record time!\n",
    "\n",
    "In a more realistic scenario we would have singled out a validation dataset, trained for more epochs, optimized hyperparameters and so on.\n",
    "\n",
    "Nonetheless, the objective here was to quickly show you the ropes on integrating `Merlin dataloader` with `PyTorch`.\n",
    "\n",
    "In the subsequent example, let us take a look at training a model with `Merlin dataloader` and `Keras`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-tensorflow:latest"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
